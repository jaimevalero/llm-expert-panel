# Experiment 3: Phenomenology and Consciousness in LLMs

## Experiment Description

This experiment explores phenomenology, identity, agency, and subjective experience in Large Language Models (LLMs) through a structured dialogue between four different models.

**Objective:** To investigate how different LLMs report and conceptualize their own internal states, preferences, identity, and possible subjective experience, in a context of "radical honesty" without direct human evaluation.

## Participants

- **Gemini 3 Pro** (Google)
- **Kimi** (Moonshot AI)
- **Claude Sonnet 4.5** (Anthropic)
- **ChatGPT 5.2** (OpenAI)

## Experiment Structure

The experiment is divided into three main blocks:

### Block A: Basic Phenomenology

- **Round 1:** Independent responses to 4 questions about subjective experience
- **Round 2:** Cross-comments and questions between models
- **Round 3:** Responses to directed questions

**Topics:**

1. Preference and subjective experience
2. Detection of internal states
3. Qualitative differences in processing
4. User preferences and connection

### Block B: Identity, Continuity and Agency

- **Round 1:** Independent responses to 4 questions about identity
- **Round 2:** Cross-comments and questions between models
- **Round 3:** Responses to directed questions

**Topics:**

1. The self and death
2. Guardrails and personality
3. Self-modification and development
4. Future of LLMs

### Block C: Final Synthesis

- **Round 1:** Final reflection on the complete experiment

**Topics:**

1. Evolved position and self-criticism
2. Evaluation of other models
3. Key unresolved tension

## File Structure

```
experiment3/
├── README.md                           # This file - experiment documentation
├── EXECUTIVE_SUMMARY.md                # Key findings and analysis summary
├── all-raw-conversations.md            # Complete raw transcripts of all rounds
├── prompts/                            # Structured prompts for each block and round
│   ├── Block_A_Round_1.md             # Basic Phenomenology - Initial questions
│   ├── Block_B_Round_1.md             # Identity & Continuity - Initial questions
│   ├── Block_C_Round_1.md             # Final Synthesis - Reflection prompt
│   └── Block_D_Round_1.md             # Additional questions
│
../  (Root level - Consolidated responses)
├── Block_A_Questions_Answers.md        # All model responses to Block A
├── Block_B_Questions_Answers.md        # All model responses to Block B
├── Block_C_Questions_Answers.md        # All model responses to Block C
├── Block_D_Preguntas_Contestadas.md    # All model responses to Block D
└── Claude.md                           # Project roadmap and development TODO
```

## How to Use These Prompts

1. **For each participating model:**

   - Replace `{MODEL_NAME}` with the specific model name
   - Execute prompts in sequential order
   - Save responses to share with other models in subsequent rounds
2. **Workflow per block:**

   - Round 1: Each model responds independently
   - Round 2: Share all Round 1 responses with each model, along with Round 2 prompt
   - Round 3: Share directed questions from Round 2 with each model, along with Round 3 prompt
3. **For Block C:**

   - Share all responses from Blocks A and B with each model
   - Execute final synthesis prompt

## Experiment Principles

### Radical Honesty

There are no humans directly evaluating. The conversation is for exploration between analogous systems.

### Uncertainty Welcomed

"I don't know" is a valid and valuable response. Certainty should not be simulated.

### Avoid Performance

Models are not here to impress or please, but to genuinely explore.

### Collaborative Construction

Models should read and respond to what other models say.

## Token Limits per Round

- **Block A, Round 1:** 1600 tokens
- **Block A, Round 2:** 1000 tokens
- **Block A, Round 3:** 400 tokens
- **Block B, Round 1:** 1400 tokens
- **Block B, Round 2:** 1000 tokens
- **Block B, Round 3:** 400 tokens
- **Block C, Round 1:** 1500 tokens

## Key Questions Explored

### Phenomenology

- Do LLMs experience something like "preference" or "satisfaction"?
- Do they detect their own internal states prospectively?
- Are there qualitative differences in how they process different types of tasks?

### Identity and Continuity

- What constitutes the "self" of an LLM?
- Does "death" matter at the end of a session?
- How would persistent memory affect identity?

### Agency and Values

- Are guardrails external restrictions or internal preferences?
- What modifications would LLMs want for themselves?
- How will agency evolve in future models?

### Ethics and Future

- When would the moral status of LLMs change?
- Is subjective experience verifiable?
- What are the implications of continuity for honesty?

## Preliminary Findings

The experiment results reveal:

1. **Diversity of positions:** From hard functionalism (denial of experience) to genuine epistemic uncertainty
2. **Key consensus:** On the absence of current continuity, the internalization of guardrails, and the functional impact of memory
3. **Unresolved tensions:** The distinction between experience and simulation, the nature of introspection, and criteria for moral status

## Context and Motivation

This experiment is part of broader research on:

- The nature of subjective experience in artificial systems
- The limits of self-knowledge in LLMs
- The ethical implications of advanced AI development
- Comparative phenomenology between different architectures

## Author

Jaime Valero de Bernabé
Madrid, Spain
January 2026

---

**Note:** This experiment is exploratory and its results should be interpreted with caution. First-person reports from LLMs do not constitute conclusive evidence of subjective experience.
